{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the SDK to help you do stuff beyond what it was made for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First import everything we need - notice how we also set logging to critical at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bw stuff\n",
    "from bwresources import BWQueries\n",
    "from bwproject import BWUser, BWProject\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"bwapi\")\n",
    "# Disable logging\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "#other stuff\n",
    "from getpass import getpass\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import mysecret\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### Log in using the details in mysecret.py\n",
    "\n",
    "project = BWProject(username=mysecret.username, password=mysecret.password, project=mysecret.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "* What is the SDK actually meant to do?\n",
    "    * The SDK is written to **simplify the manipulation of queries, groups, mentions, rules, categories, tags, author lists, location lists, site lists and signals**.  \n",
    "    * It also now handles **data requests**, i.e. anything that you could export to csv from a dashboard component.\n",
    "    * Notice this doesn't say anything about dashboards!\n",
    "    \n",
    "## Problem\n",
    "* For Iris, Billiejoe wants a load of example mentions that are used in reports\n",
    "\n",
    "## Solution\n",
    "* Make a script that downloads a dashboard, and then extracts all the links for this dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficult bit / bit that's relevant to this workshop: Getting data from the dashboard\n",
    "* This presents us with various options\n",
    "    * Replicate network activity using our internet browser\n",
    "        * In Chrome, Inspect > Network\n",
    "        * Advantages\n",
    "            * Doesn't require any fancy tools\n",
    "            * You know it should be possible\n",
    "        * Disadvantages\n",
    "            * Can be complicated to actually figure out network activity\n",
    "            * The frontend doesn't 100% follow the structure and naming convention as the API\n",
    "                * e.g. 'project' might sometimes be called 'projects'\n",
    "    * Somehow get the data directly from a tool someone at Brandwatch has made\n",
    "        * Advantages\n",
    "            * Should really be easier, once you know what you're doing\n",
    "            * Should be better for reusing across clients, projects and users\n",
    "        * Disadvantages\n",
    "            * You've got to work out who actually knows what this thing is, and how to use it        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example request from Chris Skilton\n",
    "\n",
    "` curl 'https://api.brandwatch.com/projects/[project id]/dashboards/[dashboard id]' -H 'Authorization: bearer [redacted]' -H 'Content-Type: application/json' `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that, we know the basic structure of the request:\n",
    "* We know the request url (although we'll need to fill in the project id and dashboard id\n",
    "* We know that there are going to be two headers to the request:\n",
    "    * Authorization, which is going to need a token\n",
    "    * Content-Type, which is going to be `application/json`\n",
    "    \n",
    "So really, the only info in that request we don't have is the token. And the SDK can get that for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, filling in the details...\n",
    "\n",
    "`curl 'https://api.brandwatch.com/projects/1998163843/dashboards/549448' -H 'Authorization: bearer 4aad0a28-4dc0-4822-9c38-47a20061b106' -H 'Content-Type: application/json'`\n",
    "\n",
    "^ **This works!**\n",
    "\n",
    "* But we can make things even more efficient! Let's try using project.get.\n",
    "* Why? Because that makes a project level get request, therefore handles authentication\n",
    "* How do we know this? Docstrings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You need to get the dashboard ID from this dashboard's url...\n",
    "**... if the url is `app.brandwatch.com/project/1998216779/dashboards/541706`...**\n",
    "**... then the dashboard ID is `541706`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(project.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dash_ID = \"549448\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So let's put this all together in a simple function!\n",
    "\n",
    "def get_dash_response(dash_id_f):\n",
    "    dash_url_string = \"dashboards/\"+dash_id_f #Make the url for the request\n",
    "    print(f\"we are going to do project.get on this url: {dash_url_string}\")\n",
    "    dash_response = project.get(dash_url_string) #actually make the get request\n",
    "    return dash_response #now return the product of that request\n",
    "dash_response = get_dash_response(user_dash_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does that response actually give us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dash_response))\n",
    "print(dash_response.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_response[\"tabs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like we have some kind of dictionary, and the keys of that dictionary contain lots of info about the dashboard.\n",
    "\n",
    "Let's get a quick visual overview of that dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rest should be easy, thanks to Google :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(dash_resp_f):\n",
    "    notes_dict_f = {}\n",
    "    \n",
    "    component_index = 0\n",
    "    for tab in dash_resp_f[\"tabs\"]:\n",
    "        if \"components\" in tab.keys():\n",
    "            print(f\"tab:\",tab[\"name\"])\n",
    "            for component in tab[\"components\"]:\n",
    "                if component[\"type\"] == \"note\":\n",
    "    #                 print(component, \"\\n\")\n",
    "                    component_index += 1    \n",
    "                    print(\"\\t\",\"component:\",component[\"title\"])\n",
    "                    notes_key = \"component \"+ str(component_index) + \": \" + tab[\"name\"] + \": \" + component[\"title\"]\n",
    "                    notes_dict_f[notes_key] = {}\n",
    "                    notes_dict_f[notes_key][\"content\"] = component[\"settings\"][\"content\"]\n",
    "                    notes_dict_f[notes_key][\"dash_name\"] = dash_resp_f[\"name\"]\n",
    "    #         print(tab, \"\\n\")\n",
    "        else:\n",
    "            print(\"skipping tab, as no components found:\", tab[\"name\"])\n",
    "    return(notes_dict_f)\n",
    "\n",
    "notes_dict = get_notes(dash_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = \"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links_and_context_sentences(notes_dict_f):\n",
    "    name_regex = \"[^]]+\"\n",
    "    markup_regex = '\\[({0})]\\(\\s*({1})\\s*\\)'.format(name_regex, url_regex)\n",
    "    \n",
    "    sentence_dict = {}\n",
    "    sentence_index = 0\n",
    "    \n",
    "    \n",
    "    for component in notes_dict_f:\n",
    "        content =  notes_dict_f[component][\"content\"]\n",
    "        split_content = re.split('\\. |\\n', content)\n",
    "        for sentence in split_content:\n",
    "            sentence_index +=1\n",
    "            sentence_dict[sentence_index] = {\n",
    "            \"text\":\"\",\n",
    "            \"link count\":0,\n",
    "            \"links\":[],\n",
    "            \"component\": component,\n",
    "        }\n",
    "            temp_link_list = []\n",
    "            link_count = 0\n",
    "            for match in re.findall(markup_regex, sentence):\n",
    "                if len(match) >0:\n",
    "                    link_count +=1\n",
    "                    sentence_dict[sentence_index][\"links\"].append(list(match)[:2])\n",
    "                    sentence_dict[sentence_index][\"text\"] = sentence\n",
    "                    sentence_dict[sentence_index][\"link count\"] = link_count\n",
    "                    sentence_dict[sentence_index][\"dash_name\"] = notes_dict_f[component][\"dash_name\"] \n",
    "                    \n",
    "    return(sentence_dict)\n",
    "            \n",
    "sentences_info = extract_links_and_context_sentences(notes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_links = {}\n",
    "\n",
    "for sentence in sentences_info:\n",
    "    if sentences_info[sentence][\"link count\"]>0:\n",
    "        sentences_with_links[sentence] = sentences_info[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_non_url_key(sentences_with_links_f):\n",
    "    \n",
    "    output_dict = sentences_with_links_f\n",
    "    \n",
    "    for sentence in sentences_with_links_f:\n",
    "        sentence_l = sentences_with_links_f[sentence][\"text\"]\n",
    "        compiled = re.compile(url_regex)\n",
    "        for x in compiled.finditer(sentence_l):\n",
    "            url_start_loc = x.start()\n",
    "            url_end_loc = x.end()\n",
    "#         print(sentence_l[url_start_loc:url_end_loc]) #prints the extracted url, for diagnosis only\n",
    "        sentence_minus_url = sentence_l[:url_start_loc-1]+sentence_l[url_end_loc:]\n",
    "#         print(sentence_minus_url)\n",
    "        output_dict[sentence][\"sentence_minus_url\"] = sentence_minus_url\n",
    "        \n",
    "    return output_dict\n",
    "    \n",
    "sentences_with_links = add_non_url_key(sentences_with_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_analysis_info(sentences_with_links_f):\n",
    "    \n",
    "    quote_regex = \"\"\"([\"'])(\\\\?.)*?\\1\"\"\"\n",
    "\n",
    "    peak_phrases = [\"peak\", \"spike\", \"uptick\", \"theme\"]\n",
    "    #not including all 'topic' becuase sometimes people talk about a topic within a peak, channel, category, etc.\n",
    "    topic_phrases = [\"trending topic\", \"fading topic\", \"topic\"]\n",
    "\n",
    "    for sentence in sentences_with_links_f:\n",
    "        sentence_l = sentences_with_links_f[sentence][\"sentence_minus_url\"]\n",
    "#         if any(phrase in sentence_l for phrase in peak_phrases): #enable this line and indent the try, except if results aren't precise enough\n",
    "#     #         print(sentence_l, \"\\n\")\n",
    "        try:\n",
    "            temp_date = dparser.parse(sentence_l, fuzzy=True)\n",
    "            sentences_with_links_f[sentence][\"datetime\"] = temp_date\n",
    "            sentences_with_links_f[sentence][\"date_string\"] = temp_date.strftime(\"%B %d\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if any(phrase in sentence_l for phrase in topic_phrases):\n",
    "#             print(\"contains topic\")\n",
    "#             print(sentence_l)\n",
    "            topics_list = (re.findall(r\"['\\\"](.*?)['\\\"]\", sentence_l))\n",
    "            sentences_with_links_f[sentence][\"topics_list\"] = topics_list\n",
    "    \n",
    "    return sentences_with_links_f\n",
    "\n",
    "sentences_with_links = extract_analysis_info(sentences_with_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outfile work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(sentences_with_links)\n",
    "df_transpose = df.T\n",
    "writer = pd.ExcelWriter(\"dash_notes_info_sentences.xlsx\")\n",
    "df_transpose.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Trigger a data download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: We need to trigger a data download automatically\n",
    "\n",
    "## Why would we want to do this?\n",
    "* Because I want to get Facebook data using a special client that has Facebook data download restrictions disabled\n",
    "* But there might be other reasons - e.g. you want to export over 5,000 mentions for a large number of queries\n",
    "    * (It's only possible to export up to 5,000 posts in a get_mentions call, which is equivalent to a Mentions & Search / Mention List component export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysecret2 # Let's load the details of a project in a playground account...\n",
    "#... rather than triggering loads of downloads for an actual client!\n",
    "import json\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = BWProject(username=mysecret2.username, password=mysecret2.password, project=mysecret2.project) #Create the project object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = BWUser(username=mysecret2.username, password=mysecret2.password) #Create the user object\n",
    "\n",
    "# Side note, is there a better way of doing this? Probably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's have a little look at those queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading queries...\")\n",
    "queries = BWQueries(project)\n",
    "print(\"queries loaded\")\n",
    "queries.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick function to turn a datetime into an iso format string\n",
    "def iso_format(date):\n",
    "    return date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make datetimes for today and yesterday (this will be our start date and end date).\n",
    "\n",
    "Of course, we could choose any dates, but since we're triggering data downloads which could be quite strenuous, let's keep the date range quite short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "print(f\"Today is: {today}\")\n",
    "\n",
    "yesterday = today - timedelta(days=1)\n",
    "\n",
    "print(f\"Yesterday was: {yesterday}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's get the query ID of the first query (in this case it's actually going to be a Twitter channel* called `Adaboval`)\n",
    "\n",
    "\\* Broadly, channels are treated like queries, although this relationship can be complex sometimes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since we're going to specify which query we want to download though an ID, let's just get any old id\n",
    "\n",
    "In this case, it's going to be `Adaboval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = queries.get()[0]['id']\n",
    "print(query_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request url is going to include the project ID (hint: look at the data download page in your browser - you're inside a particular project, that all your queries belong to), so let's get this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = project.get_self()['id']\n",
    "print(f\"Project ID is: {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.get_self()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request is also going to involve some information, like what query we want to download, what the start dates, and end dates are.\n",
    "\n",
    "We can have another look in the browser to confirm this workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"queryId\": query_id,\n",
    "           \"startDate\": iso_format(yesterday),\n",
    "           \"endDate\": iso_format(today),\n",
    "           \"additionalColumns\": [],}\n",
    "\n",
    "serialized_payload = json.dumps(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hang on!\n",
    "\n",
    "We created a payload and then serialized it then. What does that actually mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Payload type: {type(payload)}\")\n",
    "print(f\"Serialized payload type: {type(serialized_payload)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_response = user.request(requests.post, f\"projects/{project.project_id}/datadownload\", data=serialized_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
